"""
æ™ºè°±AI GLMå¤§æ¨¡å‹APIè°ƒç”¨æœåŠ¡
ç”¨äºç”Ÿæˆèµ„äº§åˆ†ææŠ¥å‘Š
ä½¿ç”¨requestsç›´æ¥è°ƒç”¨ï¼Œé¿å…openai SDKç‰ˆæœ¬å†²çª
"""

import json
import requests
from datetime import datetime, timedelta
from decimal import Decimal
from config.report_prompts import (
    get_weekly_report_prompt,
    get_monthly_report_prompt,
    get_yearly_report_prompt,
    get_custom_report_prompt,
    PROMPT_VERSION
)

class ZhipuAiService:
    """æ™ºè°±AI GLMæ¨¡å‹æœåŠ¡ç±»"""
    
    def __init__(self, api_token, model="glm-4-flash"):
        """
        åˆå§‹åŒ–æœåŠ¡
        :param api_token: æ™ºè°±AI API Key
        :param model: æ¨¡å‹åç§°ï¼ˆé»˜è®¤glm-4-flashï¼‰
        """
        self.api_token = api_token
        self.model = model
        self.base_url = "https://open.bigmodel.cn/api/paas/v4/"
        print(f"âœ“ æ™ºè°±AIæœåŠ¡åˆå§‹åŒ–æˆåŠŸ - æ¨¡å‹: {model}")
    
    def _call_api(self, prompt, max_tokens=None, retry_count=3, retry_delay=2):
        """
        è°ƒç”¨æ™ºè°±AI GLM APIï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        :param prompt: æç¤ºè¯
        :param max_tokens: æœ€å¤§tokenæ•°ï¼ˆNoneè¡¨ç¤ºä¸é™åˆ¶ï¼‰
        :param retry_count: é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰
        :param retry_delay: é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼Œé»˜è®¤2ç§’ï¼‰
        :return: APIå“åº”å†…å®¹
        """
        import time
        
        for attempt in range(retry_count):
            try:
                if attempt > 0:
                    print(f"\n[é‡è¯•] ç¬¬{attempt + 1}æ¬¡å°è¯•...")
                    time.sleep(retry_delay * attempt)  # æŒ‡æ•°é€€é¿
                
                print(f"\n=== å¼€å§‹è°ƒç”¨API ===")
                print(f"Model: {self.model}")
                print(f"Max tokens: {'ä¸é™åˆ¶' if max_tokens is None else max_tokens}")
                print(f"Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")
                
                # æ„å»ºAPIè°ƒç”¨å‚æ•°
                api_params = {
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¸ªäººèµ„äº§ç®¡ç†é¡¾é—®ï¼Œæ“…é•¿åˆ†æç”¨æˆ·çš„èµ„äº§é…ç½®ã€æ”¶ç›Šæƒ…å†µå’Œé£é™©æ§åˆ¶ã€‚è¯·ç”¨ä¸“ä¸šã€å®¢è§‚çš„è¯­è¨€ä¸ºç”¨æˆ·æä¾›æ·±åº¦åˆ†æå’Œå»ºè®®ã€‚"
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "temperature": 0.7
                }
                
                # åªæœ‰å½“max_tokensä¸ä¸ºNoneæ—¶æ‰è®¾ç½®
                if max_tokens is not None:
                    api_params["max_tokens"] = max_tokens
                
                # ä½¿ç”¨requestsç›´æ¥è°ƒç”¨API
                headers = {
                    "Authorization": f"Bearer {self.api_token}",
                    "Content-Type": "application/json"
                }
                
                response = requests.post(
                    f"{self.base_url}chat/completions",
                    headers=headers,
                    json=api_params,
                    timeout=300  # å¢åŠ åˆ°5åˆ†é’Ÿè¶…æ—¶ï¼Œé€‚åº”é•¿æŠ¥å‘Šç”Ÿæˆ
                )
                
                response.raise_for_status()  # æ£€æŸ¥HTTPé”™è¯¯
            
                result_json = response.json()
                
                # è¯¦ç»†è°ƒè¯•ä¿¡æ¯
                print(f"\n[APIå“åº”è°ƒè¯•]")
                print(f"- HTTPçŠ¶æ€ç : {response.status_code}")
                print(f"- å“åº”choicesé•¿åº¦: {len(result_json.get('choices', []))}")
                
                if 'choices' not in result_json or len(result_json['choices']) == 0:
                    raise Exception("APIè¿”å›æ•°æ®æ ¼å¼é”™è¯¯")
                
                result = result_json['choices'][0]['message']['content']
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
                if result is None:
                    print(f"âš ï¸ è­¦å‘Š: APIè¿”å›å†…å®¹ä¸ºNone")
                    result = ""
                elif not result or result.strip() == "":
                    print(f"âš ï¸ è­¦å‘Š: APIè¿”å›ç©ºå­—ç¬¦ä¸²")
                    
                # æ£€æŸ¥finish_reason
                if 'finish_reason' in result_json['choices'][0]:
                    finish_reason = result_json['choices'][0]['finish_reason']
                    print(f"- finish_reason: {finish_reason}")
                    if finish_reason == 'length':
                        print(f"âš ï¸ è­¦å‘Š: å“åº”å› è¾¾åˆ°max_tokensé™åˆ¶è€Œè¢«æˆªæ–­ï¼")
                    elif finish_reason == 'stop':
                        print(f"âœ“ å“åº”æ­£å¸¸ç»“æŸ")
                        
                print(f"âœ“ APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(result)} å­—ç¬¦")
                return result
                    
            except requests.exceptions.HTTPError as e:
                # è·å–é”™è¯¯å“åº”è¯¦æƒ…
                error_response = None
                try:
                    error_response = e.response.json()
                except:
                    error_response = e.response.text
                
                print(f"\nâœ— APIè°ƒç”¨å¤±è´¥ (HTTP {e.response.status_code})")
                print(f"é”™è¯¯å“åº”: {error_response}")
                
                # 429é”™è¯¯éœ€è¦é‡è¯•
                if e.response.status_code == 429:
                    print(f"\nâš ï¸ APIé€Ÿç‡é™åˆ¶ (429 Too Many Requests)")
                    if attempt < retry_count - 1:
                        wait_time = retry_delay * (attempt + 1)
                        print(f"å°†åœ¨{wait_time}ç§’åé‡è¯•...")
                        continue  # é‡è¯•
                    else:
                        print(f"å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                        raise Exception(f"APIè°ƒç”¨å¤±è´¥(é€Ÿç‡é™åˆ¶): è¯·ç¨åå†è¯•")
                # 400é”™è¯¯ - è¯·æ±‚å‚æ•°é—®é¢˜
                elif e.response.status_code == 400:
                    print(f"\nâŒ APIè¯·æ±‚å‚æ•°é”™è¯¯ (400 Bad Request)")
                    print(f"è¯·æ±‚å‚æ•°:")
                    print(f"- Model: {api_params.get('model')}")
                    print(f"- Temperature: {api_params.get('temperature')}")
                    print(f"- Max tokens: {api_params.get('max_tokens', 'None')}")
                    print(f"- Messagesæ•°é‡: {len(api_params.get('messages', []))}")
                    if error_response:
                        print(f"\næ™ºè°±AIé”™è¯¯è¯¦æƒ…: {error_response}")
                    raise Exception(f"APIè¯·æ±‚å‚æ•°é”™è¯¯: {error_response}")
                else:
                    import traceback
                    error_detail = traceback.format_exc()
                    print(f"\nâœ— APIè°ƒç”¨å¤±è´¥ (HTTPé”™è¯¯)")
                    print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                    print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
                    print(f"è¯¦ç»†å †æ ˆ:\n{error_detail}")
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
            except requests.exceptions.RequestException as e:
                import traceback
                error_detail = traceback.format_exc()
                print(f"\nâœ— APIè°ƒç”¨å¤±è´¥ (ç½‘ç»œé”™è¯¯)")
                print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
                print(f"è¯¦ç»†å †æ ˆ:\n{error_detail}")
                raise Exception(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                print(f"\nâœ— APIè°ƒç”¨å¤±è´¥")
                print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
                print(f"è¯¦ç»†å †æ ˆ:\n{error_detail}")
                raise Exception(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        raise Exception(f"APIè°ƒç”¨å¤±è´¥: å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def _preprocess_data_with_ai(self, compressed_text, enable_ai_insights=False):  
        """
        ç¬¬äºŒé˜¶æ®µï¼šå¯¹çº¯æ–‡æœ¬æ ¼å¼çš„æ•°æ®è¿›è¡Œ AI é¢„åˆ†æ
        æ³¨æ„ï¼šè¾“å…¥å’Œè¾“å‡ºå…¨éƒ¨ä¸ºçº¯æ–‡æœ¬æ ¼å¼ï¼Œä¸ä½¿ç”¨ JSON
        :param compressed_text: å‹ç¼©åçš„çº¯æ–‡æœ¬æ•°æ®
        :param enable_ai_insights: æ˜¯å¦å¯ç”¨AIæ´å¯Ÿï¼ˆé»˜è®¤å…³é—­ä»¥èŠ‚çœAPIè°ƒç”¨ï¼‰
        :return: AIæ´å¯Ÿçš„çº¯æ–‡æœ¬æ ¼å¼ï¼Œå¦‚æœæœªå¯ç”¨åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        print("\n" + "="*80)
        print("[ç¬¬äºŒé˜¶æ®µ] AIæ•°æ®é¢„åˆ†æå¼€å§‹")
        print("="*80)
        
        # å¦‚æœæœªå¯ç”¨AIæ´å¯Ÿï¼Œç›´æ¥è¿”å›ç©ºå­—ç¬¦ä¸²
        if not enable_ai_insights:
            print("[è·³è¿‡] AIæ´å¯Ÿå·²ç¦ç”¨ï¼Œç›´æ¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µ")
            print("[æç¤º] è¿™å°†èŠ‚çœä¸€æ¬¡APIè°ƒç”¨ï¼Œé¿å…é€Ÿç‡é™åˆ¶")
            print("\n" + "="*80)
            print("[ç¬¬äºŒé˜¶æ®µ] AIæ•°æ®é¢„åˆ†æç»“æŸ")
            print("="*80 + "\n")
            return ""  # è¿”å›ç©ºå­—ç¬¦ä¸²è€Œä¸æ˜¯None
        
        print(f"\n[æ•°æ®è¾“å…¥] æ–‡æœ¬é•¿åº¦: {len(compressed_text)} å­—ç¬¦")
        print(f"\n[æ–‡æœ¬é¢„è§ˆ]\n{compressed_text[:500]}...\n")
        
        # æ„é€ AIé¢„åˆ†ææç¤ºè¯ï¼ˆè¦æ±‚è¿”å›çº¯æ–‡æœ¬ï¼‰
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„èµ„äº§ç®¡ç†åˆ†æå¸ˆï¼Œè¯·å¯¹ä»¥ä¸‹èµ„äº§æ•°æ®è¿›è¡Œå…¨é¢åˆ†æã€‚

{compressed_text}

è¯·ä»¥çº¯æ–‡æœ¬æ ¼å¼è¿”å›åˆ†æç»“æœï¼Œä¸è¦ä½¿ç”¨JSONæ ¼å¼ã€‚

è¯·æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼š

ã€æ•´ä½“æ€»ç»“ã€‘
(ç”¨ 60 å­—ä»¥å†…æ€»ç»“èµ„äº§æ•´ä½“æƒ…å†µ)

ã€å…³é”®äº®ç‚¹ã€‘
- äº®ç‚¹1ï¼š...
- äº®ç‚¹2ï¼š...
- äº®ç‚¹3ï¼š...

ã€éœ€è¦å…³æ³¨çš„é—®é¢˜ã€‘
- é—®é¢˜1ï¼š...
- é—®é¢˜2ï¼š...

ã€é…ç½®åˆ†æã€‘
(ç”¨ 40 å­—ä»¥å†…åˆ†æèµ„äº§é…ç½®æƒ…å†µ)

ã€å¥åº·è¯„åˆ†ã€‘
è¯„åˆ†ï¼š75/100

åˆ†æè¦æ±‚ï¼š
1. å…¨é¢å®¡è§†æ‰€æœ‰åˆ†ç±»å’Œé¡¹ç›®
2. è¯†åˆ«èµ„äº§é…ç½®ä¸åˆç†ä¹‹å¤„
3. æ ‡æ³¨é«˜æµªè´¹ç‡åˆ†ç±»
4. å‘ç°æ½œåœ¨é£é™©
5. åªè¿”å›çº¯æ–‡æœ¬ï¼Œä¸è¦JSONæˆ–Markdownæ ¼å¼
"""
        
        print(f"\n[AIè¯·æ±‚] Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")
        print(f"\n[Promptå†…å®¹]\n{prompt}")
        print("\n" + "-"*80)
        
        try:
            print("\n[è°ƒç”¨API] å¼€å§‹è°ƒç”¨æ™ºè°±AI...")
            response_text = self._call_api(prompt)
            
            print(f"\n[APIå“åº”] åŸå§‹å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
            print(f"\n[AIæ´å¯Ÿ - çº¯æ–‡æœ¬æ ¼å¼]\n{response_text}")
            print("\n" + "-"*80)
            
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼ˆç§»é™¤å¯èƒ½çš„ä»£ç æ ‡è®°ï¼‰
            cleaned_text = response_text.strip()
            if '```' in cleaned_text:
                # å¦‚æœAIä¸å¬è¯è¿˜æ˜¯è¿”å›äº†ä»£ç å—ï¼Œå°±æå–å‡ºæ¥
                parts = cleaned_text.split('```')
                if len(parts) >= 3:
                    cleaned_text = parts[1].strip()
                    if cleaned_text.startswith('text') or cleaned_text.startswith('plaintext'):
                        cleaned_text = '\n'.join(cleaned_text.split('\n')[1:])
                    print("[æ–‡æœ¬æ¸…ç†] ç§»é™¤äº†```æ ‡è®°")
            
            print(f"\n[âœ“ æˆåŠŸ] AIé¢„åˆ†æå®Œæˆï¼Œè¿”å›çº¯æ–‡æœ¬æ´å¯Ÿ")
            print("\n" + "="*80)
            print("[ç¬¬äºŒé˜¶æ®µ] AIæ•°æ®é¢„åˆ†æç»“æŸ")
            print("="*80 + "\n")
            
            return cleaned_text
                
        except Exception as e:
            print(f"\n[å¼‚å¸¸] âœ— AIé¢„åˆ†æå‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            print(f"[å †æ ˆä¿¡æ¯]\n{traceback.format_exc()}")
            print("\n[é™çº§å¤„ç†] è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œç»§ç»­æ‰§è¡Œ")
            print("\n" + "="*80)
            print("[ç¬¬äºŒé˜¶æ®µ] AIæ•°æ®é¢„åˆ†æç»“æŸ")
            print("="*80 + "\n")
            return ""
    
    def _compress_data_to_text(self, asset_data):
        """
        å°†ç»“æ„åŒ–æ•°æ®å‹ç¼©ä¸ºç®€æ´çš„æ–‡æœ¬æ ¼å¼
        :param asset_data: ç»“æ„åŒ–æ•°æ®
        :return: å‹ç¼©åçš„æ–‡æœ¬
        """
        lines = []
        
        # æŠ¥å‘ŠæœŸé—´
        period = asset_data['period']
        lines.append(f"ã€æŠ¥å‘ŠæœŸé—´ã€‘{period['start_date']} è‡³ {period['end_date']} (å…±{period['days']}å¤©)")
        lines.append("")
        
        # å›ºå®šèµ„äº§
        fa = asset_data['fixed_assets']
        lines.append("ã€å›ºå®šèµ„äº§ã€‘")
        lines.append(f"- èµ„äº§æ€»æ•°: {fa['total_assets']}é¡¹")
        lines.append(f"- åŸå§‹æ€»å€¼: Â¥{fa['total_original_value']:,.2f}")
        lines.append(f"- å½“å‰æ€»å€¼: Â¥{fa['total_current_value']:,.2f}")
        lines.append(f"- ç´¯è®¡æŠ˜æ—§: Â¥{fa['total_depreciation']:,.2f}")
        lines.append(f"- æŠ˜æ—§ç‡: {fa['depreciation_rate']}%")
        lines.append(f"- æœŸé—´æ”¶å…¥: Â¥{fa['total_income']:,.2f}")
        
        # åˆ†ç±»æ˜ç»†ï¼ˆæ˜¾ç¤ºå…¨éƒ¨ï¼‰
        if fa['category_stats']:
            lines.append(f"- åˆ†ç±»æ˜ç»†: {len(fa['category_stats'])}ä¸ªåˆ†ç±»")
            for cat_name, cat_data in fa['category_stats'].items():
                lines.append(f"  * {cat_name}: {cat_data['count']}é¡¹, å½“å‰ä»·å€¼Â¥{cat_data['total_value']:,.2f}")
        
        # çŠ¶æ€ç»Ÿè®¡
        if fa['status_stats']:
            lines.append("- èµ„äº§çŠ¶æ€:")
            for status, count in fa['status_stats'].items():
                lines.append(f"  * {status}: {count}é¡¹")
        lines.append("")
        
        # è™šæ‹Ÿèµ„äº§
        va = asset_data['virtual_assets']
        lines.append("ã€è™šæ‹Ÿèµ„äº§ï¼ˆé¢„ä»˜æƒç›Šï¼‰ã€‘")
        lines.append(f"- é¡¹ç›®æ€»æ•°: {va['total_projects']}é¡¹")
        lines.append(f"- æ€»æŠ•å…¥: Â¥{va['total_amount']:,.2f}")
        lines.append(f"- æ´»è·ƒé¡¹ç›®: {va['active_count']}é¡¹, å‰©ä½™ä»·å€¼Â¥{va['total_remaining_value']:,.2f}")
        lines.append(f"- è¿‡æœŸé¡¹ç›®: {va['expired_count']}é¡¹, æµªè´¹ä»·å€¼Â¥{va['total_wasted_value']:,.2f}")
        lines.append(f"- æœªå¼€å§‹: {va['not_started_count']}é¡¹, ä»·å€¼Â¥{va['not_started_value']:,.2f}")
        lines.append(f"- åˆ©ç”¨ç‡: {va['utilization_rate']}%")
        lines.append(f"- æµªè´¹ç‡: {va['waste_rate']}%")
        
        # è™šæ‹Ÿèµ„äº§åˆ†ç±»æ˜ç»†ï¼ˆæ˜¾ç¤ºå…¨éƒ¨ï¼‰
        if va['category_stats']:
            lines.append(f"- è™šæ‹Ÿèµ„äº§åˆ†ç±»: {len(va['category_stats'])}ä¸ªåˆ†ç±»")
            for cat_name, cat_data in va['category_stats'].items():
                lines.append(f"  * {cat_name}: {cat_data['count']}é¡¹, æ€»æŠ•å…¥Â¥{cat_data['total_amount']:,.2f}, æµªè´¹Â¥{cat_data['wasted_value']:,.2f}")
        
        # å³å°†è¿‡æœŸé¡¹ç›®ï¼ˆæ˜¾ç¤ºå…¨éƒ¨ï¼‰
        if va['expiring_soon']:
            lines.append(f"- å³å°†è¿‡æœŸé¡¹ç›®({len(va['expiring_soon'])}):")
            for proj in va['expiring_soon']:
                lines.append(f"  ! {proj['name']} - è¿˜å‰©{proj['days_left']}å¤©, ä»·å€¼Â¥{proj['remaining_value']:,.2f}")
        lines.append("")
        
        # ç»¼åˆè§†å›¾
        comp = asset_data['comprehensive']
        lines.append("ã€ç»¼åˆè§†å›¾ã€‘")
        lines.append(f"- æœ‰å½¢èµ„äº§ä»·å€¼: Â¥{comp['tangible_assets_value']:,.2f}")
        lines.append(f"- æ´»è·ƒæƒç›Šä»·å€¼: Â¥{comp['active_rights_value']:,.2f}")
        lines.append(f"- æœªå¼€å§‹æƒç›Š: Â¥{comp['not_started_rights_value']:,.2f}")
        lines.append(f"- ç»¼åˆæ´»è·ƒä»·å€¼: Â¥{comp['combined_active_value']:,.2f}")
        lines.append(f"- è¯´æ˜: {comp['note']}")
        
        return "\n".join(lines)
    
    def _get_previous_period_data(self, user_id, start_date, end_date):
        """
        è·å–ä¸Šä¸€æœŸçš„æ•°æ®ï¼ˆåŒç­‰æ—¶é•¿ï¼‰
        :param user_id: ç”¨æˆ·ID
        :param start_date: å½“å‰æœŸå¼€å§‹æ—¥æœŸ
        :param end_date: å½“å‰æœŸç»“æŸæ—¥æœŸ
        :return: ä¸ŠæœŸæ•°æ®æˆ–None
        """
        from datetime import datetime, timedelta
        
        # è®¡ç®—æ—¶é—´è·¨åº¦
        if isinstance(start_date, str):
            start_date = datetime.strptime(start_date, '%Y-%m-%d').date()
        if isinstance(end_date, str):
            end_date = datetime.strptime(end_date, '%Y-%m-%d').date()
        
        period_length = (end_date - start_date).days
        
        # è®¡ç®—ä¸ŠæœŸæ—¶é—´èŒƒå›´
        prev_end = start_date - timedelta(days=1)
        prev_start = prev_end - timedelta(days=period_length)
        
        print(f"[ä¸ŠæœŸæŸ¥è¯¢] è®¡ç®—ä¸ŠæœŸæ—¶é—´: {prev_start} è‡³ {prev_end}")
        
        try:
            # å°è¯•æŸ¥è¯¢ä¸ŠæœŸæ•°æ®
            previous_data = self.prepare_asset_data(user_id, prev_start, prev_end)
            return previous_data
        except Exception as e:
            print(f"[ä¸ŠæœŸæŸ¥è¯¢] æœªæ‰¾åˆ°ä¸ŠæœŸæ•°æ®: {str(e)}")
            return None
    
    def _generate_comparison_text(self, current_data, previous_data):
        """
        ç”Ÿæˆå½“å‰æœŸä¸ä¸ŠæœŸçš„å¯¹æ¯”åˆ†ææ–‡æœ¬
        :param current_data: å½“å‰æœŸæ•°æ®
        :param previous_data: ä¸ŠæœŸæ•°æ®
        :return: å¯¹æ¯”åˆ†ææ–‡æœ¬
        """
        if not previous_data:
            return ""
        
        lines = []
        lines.append("ã€ä¸ŠæœŸæ•°æ®å¯¹æ¯”ã€‘")
        lines.append("")
        
        # å›ºå®šèµ„äº§å¯¹æ¯”
        curr_fa = current_data['fixed_assets']
        prev_fa = previous_data['fixed_assets']
        
        lines.append("å›ºå®šèµ„äº§å˜åŒ–:")
        
        # æ€»ä»·å€¼å¯¹æ¯”
        value_change = curr_fa['total_current_value'] - prev_fa['total_current_value']
        value_change_pct = (value_change / prev_fa['total_current_value'] * 100) if prev_fa['total_current_value'] > 0 else 0
        lines.append(f"- å½“å‰æ€»å€¼: Â¥{curr_fa['total_current_value']:,.2f} (ä¸ŠæœŸÂ¥{prev_fa['total_current_value']:,.2f}, {'+' if value_change >= 0 else ''}{value_change_pct:.1f}%)")
        
        # æ”¶å…¥å¯¹æ¯”
        income_change = curr_fa['total_income'] - prev_fa['total_income']
        income_change_pct = (income_change / prev_fa['total_income'] * 100) if prev_fa['total_income'] > 0 else 0
        lines.append(f"- æœŸé—´æ”¶å…¥: Â¥{curr_fa['total_income']:,.2f} (ä¸ŠæœŸÂ¥{prev_fa['total_income']:,.2f}, {'+' if income_change >= 0 else ''}{income_change_pct:.1f}%)")
        
        lines.append("")
        
        # è™šæ‹Ÿèµ„äº§å¯¹æ¯”
        curr_va = current_data['virtual_assets']
        prev_va = previous_data['virtual_assets']
        
        lines.append("è™šæ‹Ÿèµ„äº§å˜åŒ–:")
        
        # åˆ©ç”¨ç‡å¯¹æ¯”
        util_change = curr_va['utilization_rate'] - prev_va['utilization_rate']
        lines.append(f"- åˆ©ç”¨ç‡: {curr_va['utilization_rate']:.1f}% (ä¸ŠæœŸ{prev_va['utilization_rate']:.1f}%, {'+' if util_change >= 0 else ''}{util_change:.1f}%)")
        
        # æµªè´¹ç‡å¯¹æ¯”
        waste_change = curr_va['waste_rate'] - prev_va['waste_rate']
        lines.append(f"- æµªè´¹ç‡: {curr_va['waste_rate']:.1f}% (ä¸ŠæœŸ{prev_va['waste_rate']:.1f}%, {'+' if waste_change >= 0 else ''}{waste_change:.1f}%)")
        
        # æµªè´¹é‡‘é¢å¯¹æ¯”
        wasted_change = curr_va['total_wasted_value'] - prev_va['total_wasted_value']
        lines.append(f"- æµªè´¹é‡‘é¢: Â¥{curr_va['total_wasted_value']:,.2f} (ä¸ŠæœŸÂ¥{prev_va['total_wasted_value']:,.2f}, {'+' if wasted_change >= 0 else ''}{wasted_change:,.2f})")
        
        return "\n".join(lines)
    
    def _generate_chart_data(self, current_data, previous_data=None):
        """
        ç”Ÿæˆå‰ç«¯å›¾è¡¨æ‰€éœ€çš„æ•°æ®
        :param current_data: å½“å‰æœŸæ•°æ®
        :param previous_data: ä¸ŠæœŸæ•°æ®ï¼ˆå¯é€‰ï¼‰
        :return: å›¾è¡¨æ•°æ®å­—å…¸
        """
        chart_data = {}
        
        # 1. èµ„äº§é…ç½®é¥¼å›¾
        chart_data['asset_allocation_pie'] = [
            {
                'name': 'å›ºå®šèµ„äº§',
                'value': float(current_data['fixed_assets']['total_current_value'])
            },
            {
                'name': 'è™šæ‹Ÿèµ„äº§',
                'value': float(current_data['virtual_assets']['total_amount'])
            }
        ]
        
        # 2. å¥åº·è¯„åˆ†é›·è¾¾å›¾ï¼ˆç¤ºä¾‹æ•°æ®ï¼Œå®é™…åº”æ ¹æ®åˆ†æè®¡ç®—ï¼‰
        fa_health = min(100, (current_data['fixed_assets']['total_current_value'] / 
                              max(1, current_data['fixed_assets']['total_original_value']) * 100))
        va_health = current_data['virtual_assets']['utilization_rate']
        income_health = min(100, (current_data['fixed_assets']['total_income'] / 1000) * 100) if current_data['fixed_assets']['total_income'] > 0 else 0
        waste_health = max(0, 100 - current_data['virtual_assets']['waste_rate'] * 3)
        
        chart_data['health_score_radar'] = [
            {'dimension': 'å›ºå®šèµ„äº§', 'score': round(fa_health * 0.25, 1)},
            {'dimension': 'è™šæ‹Ÿèµ„äº§', 'score': round(va_health * 0.25, 1)},
            {'dimension': 'æ”¶å…¥è¡¨ç°', 'score': round(income_health * 0.25, 1)},
            {'dimension': 'æµªè´¹æ§åˆ¶', 'score': round(waste_health * 0.25, 1)}
        ]
        
        # 3. å›ºå®šèµ„äº§åˆ†ç±»æŸ±çŠ¶å›¾
        if current_data['fixed_assets']['category_stats']:
            chart_data['fixed_asset_categories'] = [
                {
                    'category': cat_name,
                    'value': float(cat_data['total_value'])
                }
                for cat_name, cat_data in current_data['fixed_assets']['category_stats'].items()
            ]
        else:
            chart_data['fixed_asset_categories'] = []
        
        # 4. è™šæ‹Ÿèµ„äº§åˆ©ç”¨ç‡è¡¨æ ¼
        if current_data['virtual_assets']['category_stats']:
            chart_data['virtual_asset_utilization'] = [
                {
                    'category': cat_name,
                    'utilization': round((cat_data['total_amount'] - cat_data['wasted_value']) / 
                                        max(1, cat_data['total_amount']) * 100, 1),
                    'waste': round(cat_data['wasted_value'] / 
                                  max(1, cat_data['total_amount']) * 100, 1)
                }
                for cat_name, cat_data in current_data['virtual_assets']['category_stats'].items()
            ]
        else:
            chart_data['virtual_asset_utilization'] = []
        
        return chart_data
    
    
    def prepare_asset_data(self, user_id, start_date, end_date):
        """
        å‡†å¤‡ç”¨æˆ·èµ„äº§æ•°æ®ç”¨äºåˆ†æï¼ˆå«å›ºå®šèµ„äº§å’Œè™šæ‹Ÿèµ„äº§ï¼‰
        :param user_id: ç”¨æˆ·ID
        :param start_date: å¼€å§‹æ—¥æœŸ
        :param end_date: ç»“æŸæ—¥æœŸ
        :return: æ ¼å¼åŒ–çš„èµ„äº§æ•°æ®
        """
        from models.fixed_asset import FixedAsset
        from models.asset_income import AssetIncome
        from models.category import Category
        from models.project import Project
        from datetime import datetime
        
        print(f"[æ•°æ®æŸ¥è¯¢] å¼€å§‹å‡†å¤‡èµ„äº§æ•°æ®: {start_date} è‡³ {end_date}")
        
        # ========== å›ºå®šèµ„äº§åˆ†æ ==========
        # è·å–ç”¨æˆ·çš„å›ºå®šèµ„äº§ï¼ˆæ’é™¤å·²å¤„ç½®çš„ï¼Œä¸”åœ¨æŠ¥å‘ŠæœŸç»“æŸå‰è´­ä¹°çš„ï¼‰
        assets = FixedAsset.query.filter(
            FixedAsset.user_id == user_id,
            FixedAsset.status != 'disposed',
            FixedAsset.purchase_date <= end_date
        ).all()
        
        print(f"[æ•°æ®æŸ¥è¯¢] å›ºå®šèµ„äº§æ•°é‡: {len(assets)}")
        
        # è·å–æ—¶é—´èŒƒå›´å†…çš„æ”¶å…¥æ•°æ®
        incomes = AssetIncome.query.join(FixedAsset).filter(
            FixedAsset.user_id == user_id,
            AssetIncome.income_date >= start_date,
            AssetIncome.income_date <= end_date
        ).all()
        
        print(f"[æ•°æ®æŸ¥è¯¢] æ”¶å…¥è®°å½•æ•°é‡: {len(incomes)}")
        
        # è·å–åˆ†ç±»ä¿¡æ¯
        categories = Category.query.filter_by(user_id=user_id).all()
        
        # å›ºå®šèµ„äº§ç»Ÿè®¡æ•°æ®ï¼ˆæ·»åŠ NULLå€¼æ£€æŸ¥ï¼‰
        total_assets = len(assets)
        total_original_value = sum(
            float(asset.original_value) for asset in assets 
            if asset.original_value is not None
        )
        total_current_value = sum(
            float(asset.current_value) for asset in assets 
            if asset.current_value is not None
        )
        total_income = sum(
            float(income.amount) for income in incomes 
            if income.amount is not None
        )
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        category_stats = {}
        for category in categories:
            cat_assets = [a for a in assets if a.category_id == category.id]
            if cat_assets:
                category_stats[category.name] = {
                    'count': len(cat_assets),
                    'total_value': sum(
                        float(a.current_value) for a in cat_assets 
                        if a.current_value is not None
                    ),
                    'original_value': sum(
                        float(a.original_value) for a in cat_assets 
                        if a.original_value is not None
                    )
                }
        
        # æŒ‰çŠ¶æ€ç»Ÿè®¡
        status_stats = {}
        for asset in assets:
            status = asset.get_status_text()
            if status not in status_stats:
                status_stats[status] = 0
            status_stats[status] += 1
        
        # ========== è™šæ‹Ÿèµ„äº§ï¼ˆéšé£è€Œé€ï¼‰åˆ†æ ==========
        # è·å–ä¸æŠ¥å‘ŠæœŸç›¸å…³çš„è™šæ‹Ÿèµ„äº§é¡¹ç›®ï¼ˆæœ‰æ—¶é—´äº¤é›†çš„ï¼‰
        projects = Project.query.filter(
            Project.user_id == user_id,
            Project.start_time <= end_date,  # å¼€å§‹æ—¶é—´ä¸æ™šäºæŠ¥å‘ŠæœŸç»“æŸ
            Project.end_time >= start_date   # ç»“æŸæ—¶é—´ä¸æ—©äºæŠ¥å‘ŠæœŸå¼€å§‹
        ).all()
        
        print(f"[æ•°æ®æŸ¥è¯¢] è™šæ‹Ÿèµ„äº§é¡¹ç›®æ•°é‡: {len(projects)}")
        
        # è¿‡æ»¤æ‰æ•°æ®å¼‚å¸¸çš„é¡¹ç›®
        valid_projects = [
            p for p in projects 
            if p.total_amount is not None and p.end_time >= p.start_time
        ]
        
        if len(projects) != len(valid_projects):
            print(f"[æ•°æ®è­¦å‘Š] è¿‡æ»¤æ‰ {len(projects) - len(valid_projects)} ä¸ªå¼‚å¸¸é¡¹ç›®")
        
        # ç»Ÿè®¡è™šæ‹Ÿèµ„äº§æ•°æ®
        total_projects = len(valid_projects)
        total_project_amount = sum(float(p.total_amount) for p in valid_projects)
        
        # æŒ‰çŠ¶æ€åˆ†ç±»
        active_projects = []  # æ¶ˆè€—ä¸­
        expired_projects = []  # å·²è¿‡æœŸ
        not_started_projects = []  # æœªå¼€å§‹
        
        total_used_value = 0  # å·²æ¶ˆè€—æ€»ä»·å€¼
        total_remaining_value = 0  # å‰©ä½™æ€»ä»·å€¼ï¼ˆä»…æ´»è·ƒé¡¹ç›®ï¼‰
        total_wasted_value = 0  # æµªè´¹æ€»ä»·å€¼ï¼ˆè¿‡æœŸæœªç”¨å®Œï¼‰
        not_started_value = 0  # æœªå¼€å§‹é¡¹ç›®ä»·å€¼ï¼ˆå•ç‹¬ç»Ÿè®¡ï¼‰
        
        for project in valid_projects:
            status = project.get_status()
            values = project.calculate_values()
            
            if status == 'active':
                active_projects.append(project)
                total_used_value += values['used_cost']
                total_remaining_value += values['remaining_value']
            elif status == 'expired':
                expired_projects.append(project)
                total_used_value += values['used_cost']
                # è¿‡æœŸé¡¹ç›®çš„å‰©ä½™ä»·å€¼è§†ä¸ºæµªè´¹
                total_wasted_value += values['remaining_value']
            else:  # not_started
                not_started_projects.append(project)
                # æœªå¼€å§‹é¡¹ç›®å•ç‹¬ç»Ÿè®¡ï¼Œä¸è®¡å…¥å‰©ä½™ä»·å€¼
                not_started_value += float(project.total_amount)
        
        print(f"[æ•°æ®ç»Ÿè®¡] æ´»è·ƒ: {len(active_projects)}, è¿‡æœŸ: {len(expired_projects)}, æœªå¼€å§‹: {len(not_started_projects)}")
        
        # å³å°†è¿‡æœŸçš„é¡¹ç›®ï¼ˆ7å¤©å†…ï¼‰
        expiring_soon = []
        now = datetime.utcnow()
        for project in active_projects:
            days_left = (project.end_time - now).days
            if 0 <= days_left <= 7:
                expiring_soon.append({
                    'name': project.name,
                    'days_left': days_left,
                    'remaining_value': project.calculate_values()['remaining_value']
                })
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡è™šæ‹Ÿèµ„äº§
        project_category_stats = {}
        for category in categories:
            cat_projects = [p for p in valid_projects if p.category_id == category.id]
            if cat_projects:
                cat_total = sum(float(p.total_amount) for p in cat_projects)
                cat_wasted = 0
                for p in cat_projects:
                    if p.get_status() == 'expired':
                        cat_wasted += p.calculate_values()['remaining_value']
                
                project_category_stats[category.name] = {
                    'count': len(cat_projects),
                    'total_amount': cat_total,
                    'wasted_value': cat_wasted
                }
        
        # è™šæ‹Ÿèµ„äº§åˆ©ç”¨ç‡ï¼ˆä»…è®¡ç®—å·²å¼€å§‹çš„é¡¹ç›®ï¼‰
        started_amount = sum(
            float(p.total_amount) for p in (active_projects + expired_projects)
        )
        utilization_rate = (
            (total_used_value / started_amount * 100) 
            if started_amount > 0 else 0
        )
        
        # æµªè´¹ç‡ï¼ˆåŸºäºå·²å¼€å§‹çš„é¡¹ç›®ï¼‰
        waste_rate = (
            (total_wasted_value / started_amount * 100) 
            if started_amount > 0 else 0
        )
        
        print(f"[æ•°æ®ç»Ÿè®¡] åˆ©ç”¨ç‡: {utilization_rate:.2f}%, æµªè´¹ç‡: {waste_rate:.2f}%")
        
        return {
            # å›ºå®šèµ„äº§æ•°æ®
            'fixed_assets': {
                'total_assets': total_assets,
                'total_original_value': round(total_original_value, 2),
                'total_current_value': round(total_current_value, 2),
                'total_depreciation': round(total_original_value - total_current_value, 2),
                'total_income': round(total_income, 2),
                'depreciation_rate': round((total_original_value - total_current_value) / total_original_value * 100, 2) if total_original_value > 0 else 0,
                'category_stats': category_stats,
                'status_stats': status_stats
            },
            # è™šæ‹Ÿèµ„äº§æ•°æ®ï¼ˆéšé£è€Œé€ï¼‰
            'virtual_assets': {
                'total_projects': total_projects,
                'total_amount': round(total_project_amount, 2),
                'active_count': len(active_projects),
                'expired_count': len(expired_projects),
                'not_started_count': len(not_started_projects),
                'total_used_value': round(total_used_value, 2),
                'total_remaining_value': round(total_remaining_value, 2),  # ä»…æ´»è·ƒé¡¹ç›®
                'total_wasted_value': round(total_wasted_value, 2),
                'not_started_value': round(not_started_value, 2),  # å•ç‹¬ç»Ÿè®¡
                'utilization_rate': round(utilization_rate, 2),
                'waste_rate': round(waste_rate, 2),
                'expiring_soon': expiring_soon,
                'category_stats': project_category_stats
            },
            # ç»¼åˆè§†å›¾ï¼ˆéµå¾ªæ•°æ®é€»è¾‘éš”ç¦»åŸåˆ™ï¼‰
            'comprehensive': {
                'tangible_assets_value': round(total_current_value, 2),
                'active_rights_value': round(total_remaining_value, 2),
                'not_started_rights_value': round(not_started_value, 2),
                'combined_active_value': round(total_current_value + total_remaining_value, 2),
                'note': 'æœ‰å½¢èµ„äº§+æ´»è·ƒæƒç›Šï¼Œä¸åŒ…æ‹¬æœªå¼€å§‹é¡¹ç›®'
            },
            'period': {
                'start_date': start_date.isoformat(),
                'end_date': end_date.isoformat(),
                'days': (end_date - start_date).days + 1
            }
        }
        """
        ç”Ÿæˆç»Ÿä¸€çš„æŠ¥å‘ŠProm ptï¼ˆé€‚ç”¨äºå‘¨æŠ¥/æœˆæŠ¥/å¹´æŠ¥/è‡ªå®šä¹‰ï¼‰
        :param report_type: æŠ¥å‘Šç±»å‹ï¼šweekly/monthly/yearly/custom
        :param processed_data: å¤„ç†åçš„æ•°æ®
        :param compressed_text: å‹ç¼©åçš„æ–‡æœ¬
        :param ai_insights_text: AIæ´å¯Ÿæ–‡æœ¬
        :return: Promptå­—ç¬¦ä¸²
        """
        report_names = {
            'weekly': 'å‘¨æŠ¥',
            'monthly': 'æœˆæŠ¥',
            'yearly': 'å¹´æŠ¥',
            'custom': 'è‡ªå®šä¹‰æŠ¥å‘Š'
        }
        
        return f"""ä½ æ˜¯ä¸“ä¸šçš„ä¸ªäººèµ„äº§ç®¡ç†é¡¾é—®ã€‚åŸºäºä»¥ä¸‹æ•°æ®ç”Ÿæˆä¸€ä»½ç»“æ„å®Œæ•´ã€æ•°æ®è¯¦å®ã€ç»“è®ºæ¸…æ™°çš„èµ„äº§{report_names.get(report_type, 'æŠ¥å‘Š')}ã€‚

===== æ•°æ®æº =====
{compressed_text}{ai_insights_text}

===== è¾“å‡ºè¦æ±‚ =====
**å¿…é¡»è¿”å›ä¸¥æ ¼çš„JSONæ ¼å¼**ï¼ŒåŒ…å«ä»¥ä¸‹æ‰€æœ‰å­—æ®µï¼š

{{
    "executive_summary": {{
        "title": "ğŸ“Š æ‰§è¡Œæ‘˜è¦",
        "content": "200å­—ä»¥å†…ï¼šâ¶æ€»èµ„äº§Â¥XXä¸‡ï¼ˆå›ºå®šXX%ã€è™šæ‹ŸXX%ï¼‰â·æœ€é‡è¦å‘ç° â¸ç´§æ€¥è¡ŒåŠ¨ â¹å¥åº·è¯„åˆ†XX/100",
        "highlight": "ğŸ”´ æœ€é‡è¦çš„1-2ä¸ªç»“è®ºï¼ˆç”¨emojiå’Œæ•°æ®æ ‡è®°ï¼‰"
    }},
    
    "key_conclusions": [
        {{
            "type": "critical",
            "title": "ğŸ”´ å…³é”®å‘ç°",
            "content": "å…·ä½“æ•°æ®+å æ¯”+å½±å“",
            "action": "ç«‹å³é‡‡å–çš„è¡ŒåŠ¨"
        }},
        {{
            "type": "warning",
            "title": "âš ï¸ é‡è¦è­¦ç¤º",
            "content": "å…·ä½“æ•°æ®+å æ¯”+é£é™©",
            "action": "è¿‘æœŸéœ€è¦çš„æªæ–½"
        }},
        {{
            "type": "opportunity",
            "title": "âœ… ç§¯æä¿¡å·",
            "content": "å…·ä½“æ•°æ®+å æ¯”+æ½œåŠ›",
            "action": "ä¼˜åŒ–å»ºè®®"
        }}
    ],
    
    "fixed_asset_analysis": {{
        "summary": "å›ºå®šèµ„äº§æ€»è§ˆï¼šæ€»ä»·å€¼Â¥XXï¼Œå…±XXé¡¹ï¼Œåœ¨ç”¨XX%ï¼Œé—²ç½®XX%ï¼ŒæŠ˜æ—§Â¥XX",
        "health_status": {{
            "score": 85,
            "rating": "ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬/è¾ƒå·®",
            "trend": "ä¸Šå‡/ç¨³å®š/ä¸‹é™"
        }},
        "category_breakdown": [
            {{
                "name": "åˆ†ç±»åç§°",
                "count": æ•°é‡,
                "original_value": åŸå€¼,
                "current_value": ç°å€¼,
                "usage_rate": ä½¿ç”¨ç‡%,
                "status": "å¥åº·/æ­£å¸¸/é¢„è­¦",
                "insight": "è¯¥åˆ†ç±»çš„æ ¸å¿ƒå‘ç°å’Œå»ºè®®"
            }}
        ],
        "key_insights": [
            "æ´å¯Ÿ1ï¼šå…·ä½“åˆ†ç±»+æ•°æ®+é—®é¢˜/äº®ç‚¹",
            "æ´å¯Ÿ2ï¼šä»·å€¼å˜åŠ¨+é©±åŠ¨å› ç´ ",
            "æ´å¯Ÿ3ï¼šæŠ˜æ—§åˆç†æ€§+ä¼˜åŒ–ç©ºé—´"
        ]
    }},
    
    "virtual_asset_analysis": {{
        "summary": "è™šæ‹Ÿèµ„äº§æ€»è§ˆï¼šæ€»æŠ•å…¥Â¥XXï¼Œæ´»è·ƒXXé¡¹ï¼Œè¿‡æœŸXXé¡¹ï¼Œåˆ©ç”¨ç‡XX%ï¼Œæµªè´¹ç‡XX%",
        "efficiency_status": {{
            "utilization_rate": åˆ©ç”¨ç‡%,
            "waste_rate": æµªè´¹ç‡%,
            "rating": "ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬/è¾ƒå·®"
        }},
        "category_breakdown": [
            {{
                "name": "åˆ†ç±»åç§°",
                "total_amount": æ€»æŠ•å…¥,
                "active_value": æ´»è·ƒä»·å€¼,
                "wasted_value": æµªè´¹ä»·å€¼,
                "utilization": åˆ©ç”¨ç‡%,
                "status": "é«˜æ•ˆ/æ­£å¸¸/ä½æ•ˆ",
                "insight": "è¯¥åˆ†ç±»çš„æ ¸å¿ƒå‘ç°å’Œå»ºè®®"
            }}
        ],
        "expiring_alerts": [
            {{
                "project": "é¡¹ç›®å",
                "days_left": å‰©ä½™å¤©æ•°,
                "value": å‰©ä½™ä»·å€¼,
                "urgency": "ç´§æ€¥/é‡è¦/ä¸€èˆ¬"
            }}
        ],
        "key_insights": [
            "æ´å¯Ÿ1ï¼šTOP3é«˜æµªè´¹åˆ†ç±»+é‡‘é¢+åŸå› ",
            "æ´å¯Ÿ2ï¼šè¿‡æœŸé£é™©+åº”å¯¹æ–¹æ¡ˆ",
            "æ´å¯Ÿ3ï¼šROIåˆ†æ+ä¼˜åŒ–å»ºè®®"
        ]
    }},
    
    "income_performance": {{
        "summary": "æ”¶å…¥ï¼šæ€»è®¡Â¥XXï¼Œæ¥æºXXä¸ªåˆ†ç±»ï¼Œç¯æ¯”XX%",
        "income_structure": [
            {{"source": "æ¥æºåˆ†ç±»", "amount": é‡‘é¢, "percentage": å æ¯”%}}
        ],
        "quality_assessment": {{
            "stability": "ç¨³å®šæ€§è¯„åˆ†0-100",
            "diversity": "å¤šå…ƒåŒ–è¯„åˆ†0-100",
            "concentration_risk": "é›†ä¸­åº¦é£é™©ï¼šé«˜/ä¸­/ä½"
        }},
        "key_insights": [
            "æ´å¯Ÿ1ï¼šæ”¶å…¥ç»“æ„+ç¨³å®šæ€§",
            "æ´å¯Ÿ2ï¼šå¢é•¿æ½œåŠ›+ç“¶é¢ˆ",
            "æ´å¯Ÿ3ï¼šå¤šå…ƒåŒ–å»ºè®®"
        ]
    }},
    
    "asset_allocation_review": {{
        "current_allocation": {{
            "fixed_percentage": å›ºå®šèµ„äº§å æ¯”%,
            "virtual_percentage": è™šæ‹Ÿèµ„äº§å æ¯”%,
            "balance_score": é…ç½®å¹³è¡¡åˆ†0-100,
            "assessment": "é…ç½®è¯„ä»·ï¼šåˆç†/åé‡å›ºå®š/åé‡è™šæ‹Ÿ"
        }},
        "imbalances": [
            {{
                "issue": "å¤±è¡¡ç‚¹æè¿°",
                "current": "å½“å‰%",
                "target": "ç›®æ ‡%",
                "impact": "å½±å“åˆ†æ",
                "action": "è°ƒæ•´æ–¹æ¡ˆ"
            }}
        ],
        "optimization_plan": {{
            "target_allocation": "ç›®æ ‡é…ç½®ï¼šå›ºå®šXX%ã€è™šæ‹ŸXX%",
            "increase_categories": ["éœ€è¦å¢æŒçš„åˆ†ç±»"],
            "decrease_categories": ["éœ€è¦å‡æŒçš„åˆ†ç±»"],
            "timeline": "è°ƒæ•´æ—¶é—´è¡¨",
            "expected_benefit": "é¢„æœŸæ”¶ç›Š"
        }}
    }},
    
    "actionable_recommendations": [
        {{
            "priority": "é«˜/ä¸­/ä½",
            "category": "å›ºå®šèµ„äº§/è™šæ‹Ÿèµ„äº§/é…ç½®/æ”¶å…¥",
            "title": "å»ºè®®æ ‡é¢˜",
            "problem": "å½“å‰é—®é¢˜+æ•°æ®",
            "solution": "å…·ä½“æªæ–½+æ­¥éª¤",
            "expected_result": "é¢„æœŸæ•ˆæœ+æ—¶é—´",
            "investment": "æ‰€éœ€æŠ•å…¥ï¼ˆæ—¶é—´/é‡‘é’±ï¼‰"
        }}
    ],
    
    "risk_alerts": [
        {{
            "risk_type": "æŠ˜æ—§è´¬å€¼/è™šæ‹Ÿæµªè´¹/é…ç½®å¤±è¡¡/æ”¶å…¥é›†ä¸­",
            "severity": "é«˜/ä¸­/ä½",
            "urgency": "ç´§æ€¥/é‡è¦/ä¸€èˆ¬",
            "description": "é£é™©æè¿°+å…·ä½“èµ„äº§/é¡¹ç›®+é‡‘é¢",
            "probability": "å‘ç”Ÿæ¦‚ç‡%",
            "impact": "æ½œåœ¨æŸå¤±Â¥XXæˆ–å½±å“",
            "mitigation": "ç¼“è§£æªæ–½"
        }}
    ],
    
    "health_score": {{
        "overall_score": 75,
        "rating": "ä¼˜ç§€(90-100)/è‰¯å¥½(75-89)/ä¸€èˆ¬(60-74)/è¾ƒå·®(<60)",
        "trend": "è¾ƒä¸ŠæœŸï¼šä¸Šå‡+5/ç¨³å®š/ä¸‹é™-3",
        "breakdown": {{
            "fixed_assets": {{"score": 20, "max": 25, "comment": "è¯„ä»·"}},
            "virtual_assets": {{"score": 18, "max": 25, "comment": "è¯„ä»·"}},
            "income_performance": {{"score": 20, "max": 25, "comment": "è¯„ä»·"}},
            "allocation_balance": {{"score": 17, "max": 25, "comment": "è¯„ä»·"}}
        }},
        "improvement_suggestions": [
            "æåˆ†æªæ–½1ï¼šå…·ä½“è¡ŒåŠ¨+é¢„æœŸæå‡åˆ†æ•°",
            "æåˆ†æªæ–½2ï¼šå…·ä½“è¡ŒåŠ¨+é¢„æœŸæå‡åˆ†æ•°"
        ]
    }},
    
    "next_period_focus": [
        {{
            "task": "ä»»åŠ¡æè¿°",
            "target": "é‡åŒ–ç›®æ ‡",
            "deadline": "å®ŒæˆæœŸé™",
            "expected_impact": "é¢„æœŸæ•ˆæœ"
        }}
    ],
    
    "chart_data": {{
        "asset_allocation_pie": [
            {{"name": "å›ºå®šèµ„äº§", "value": {processed_data['fixed_assets']['total_current_value']}, "color": "#1890ff"}},
            {{"name": "è™šæ‹Ÿèµ„äº§", "value": {processed_data['virtual_assets']['total_amount']}, "color": "#52c41a"}}
        ],
        "fixed_asset_categories": [
            {{"category": "åˆ†ç±»å", "count": æ•°é‡, "value": ç°å€¼, "status": "ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬/è¾ƒå·®"}}
        ],
        "virtual_asset_utilization": [
            {{"category": "åˆ†ç±»å", "utilization": åˆ©ç”¨ç‡%, "waste": æµªè´¹ç‡%, "status": "é«˜æ•ˆ/æ­£å¸¸/ä½æ•ˆ"}}
        ],
        "income_trend": [
            {{"period": "æ—¶é—´æ®µ", "amount": é‡‘é¢}}
        ],
        "health_score_radar": [
            {{"dimension": "å›ºå®šèµ„äº§", "score": å¾—åˆ†, "fullScore": 25}},
            {{"dimension": "è™šæ‹Ÿèµ„äº§", "score": å¾—åˆ†, "fullScore": 25}},
            {{"dimension": "æ”¶å…¥è¡¨ç°", "score": å¾—åˆ†, "fullScore": 25}},
            {{"dimension": "é…ç½®åˆç†", "score": å¾—åˆ†, "fullScore": 25}}
        ],
        "waste_ranking": [
            {{"category": "é«˜æµªè´¹åˆ†ç±»", "amount": æµªè´¹é‡‘é¢, "rate": æµªè´¹ç‡%}}
        ]
    }}
}}

===== æ ¸å¿ƒè¦æ±‚ =====
1. **æ•°æ®çœŸå®æ€§**ï¼šæ‰€æœ‰æ•°å­—å¿…é¡»åŸºäºæä¾›çš„æ•°æ®ï¼Œç¦æ­¢ç¼–é€ 
2. **ç»“è®ºæ¸…æ™°**ï¼šæ¯ä¸ªåˆ†æéƒ½è¦æœ‰æ˜ç¡®ç»“è®ºï¼Œç”¨ğŸ”´âš ï¸âœ…ç­‰emojiçªå‡ºé‡ç‚¹
3. **å›¾è¡¨å®Œæ•´**ï¼šchart_dataæ‰€æœ‰å›¾è¡¨æ•°æ®å¿…é¡»å¡«å……çœŸå®æ•°å€¼
4. **åˆ†ç±»å…¨è¦†ç›–**ï¼šé€ä¸€åˆ†ææ¯ä¸ªèµ„äº§åˆ†ç±»ï¼Œä¸é—æ¼
5. **å»ºè®®å¯æ‰§è¡Œ**ï¼šå»ºè®®åŒ…å«å…·ä½“æ­¥éª¤ã€æ—¶é—´ã€é¢„æœŸæ•ˆæœ
6. **é£é™©é‡åŒ–**ï¼šé£é™©åŒ…å«ä¸¥é‡åº¦ã€ç´§æ€¥åº¦ã€æ¦‚ç‡ã€å½±å“
7. **å¥åº·è¯„åˆ†**ï¼šæœ‰æ˜ç¡®çš„è¯„åˆ†ä¾æ®å’Œè®¡ç®—é€»è¾‘
8. **JSONæ ¼å¼**ï¼šå­—ç¬¦ä¸²å€¼å†…ä¸æ¢è¡Œï¼Œä¸€è¡Œå®Œæˆ
9. **çº¯JSONè¾“å‡º**ï¼šä¸è¦ä»»ä½•``json```æ ‡è®°æˆ–å…¶ä»–æ–‡å­—
10. **ä¸­æ–‡è¡¨è¾¾**ï¼šé™¤ROIã€emojiç­‰ï¼Œå…¨éƒ¨ä½¿ç”¨ä¸­æ–‡
11. **â—ç¦æ­¢æ•°å­¦è¡¨è¾¾å¼â—**ï¼šæ‰€æœ‰æ•°å€¼å¿…é¡»æ˜¯è®¡ç®—å¥½çš„å…·ä½“æ•°å­—ï¼Œç¦æ­¢ä½¿ç”¨ 3500-3121.79 è¿™ç§è¡¨è¾¾å¼ï¼Œå¿…é¡»å†™378.21

===== ç‰¹åˆ«å¼ºè°ƒ =====
- é‡ç‚¹ç»“è®ºç”¨**åŠ ç²—**ã€ğŸ”´çº¢è‰²æ ‡è®°ã€æˆ–ğŸ’°é‡‘é¢çªå‡º
- æ¯ä¸ªåˆ†ææ¨¡å—éƒ½è¦æœ‰æ¸…æ™°çš„summaryæ€»ç»“
- chart_dataå¿…é¡»åŒ…å«æ‰€æœ‰ï¼–ç±»å›¾è¡¨çš„å®Œæ•´æ•°æ®
- key_conclusionså¿…é¡»æç‚¼ï¼“ä¸ªæœ€é‡è¦çš„å‘ç°
- æ¯ä¸ªcategory_breakdownéƒ½è¦åŒ…å«çœŸå®çš„åˆ†ç±»æ•°æ®
- æ‰€æœ‰å»ºè®®éƒ½è¦æœ‰priorityä¼˜å…ˆçº§å’Œå¯æ‰§è¡Œæ–¹æ¡ˆ

âš ï¸ **JSONæ ¼å¼è´¨é‡æ§åˆ¶** âš ï¸
1. ä¸¥ç¦åœ¨å­—ç¬¦ä¸²å†…ä½¿ç”¨æ¢è¡Œç¬¦\nï¼Œå…¨éƒ¨å†…å®¹å¿…é¡»å†™åœ¨ä¸€è¡Œå†…
2. ç¦æ­¢ä½¿ç”¨ä¸åˆæ³•çš„Unicodeå­—ç¬¦æˆ–ç‰¹æ®Šæ§åˆ¶å­—ç¬¦
3. æ‰€æœ‰é€—å·ã€å†’å·ã€æ‹¬å·å¿…é¡»æˆå¯¹å‡ºç°ï¼Œä¸èƒ½æ¼æ‰
4. æ•°ç»„æœ€åä¸€ä¸ªå…ƒç´ ã€å¯¹è±¡æœ€åä¸€ä¸ªå­—æ®µåé¢ä¸èƒ½æœ‰é€—å·
5. å­—ç¬¦ä¸²å€¼å†…çš„å¼•å·å¿…é¡»è½¬ä¹‰ï¼š\" è€Œä¸æ˜¯ "
6. è¾“å‡ºå‰è‡ªæ£€JSONæ ¼å¼ï¼Œç¡®ä¿å¯è¢«è§£æå™¨è§£æ
7. ç»å¯¹ä¸è¦è¾“å‡º ```json``` æ ‡è®°ï¼Œç›´æ¥è¾“å‡ºçº¯JSON
"""
        """
        å‡†å¤‡ç”¨æˆ·èµ„äº§æ•°æ®ç”¨äºåˆ†æï¼ˆå«å›ºå®šèµ„äº§å’Œè™šæ‹Ÿèµ„äº§ï¼‰
        :param user_id: ç”¨æˆ·ID
        :param start_date: å¼€å§‹æ—¥æœŸ
        :param end_date: ç»“æŸæ—¥æœŸ
        :return: æ ¼å¼åŒ–çš„èµ„äº§æ•°æ®
        """
        from models.fixed_asset import FixedAsset
        from models.asset_income import AssetIncome
        from models.category import Category
        from models.project import Project
        from datetime import datetime
        
        print(f"[æ•°æ®æŸ¥è¯¢] å¼€å§‹å‡†å¤‡èµ„äº§æ•°æ®: {start_date} è‡³ {end_date}")
        
        # ========== å›ºå®šèµ„äº§åˆ†æ ==========
        # è·å–ç”¨æˆ·çš„å›ºå®šèµ„äº§ï¼ˆæ’é™¤å·²å¤„ç½®çš„ï¼Œä¸”åœ¨æŠ¥å‘ŠæœŸç»“æŸå‰è´­ä¹°çš„ï¼‰
        assets = FixedAsset.query.filter(
            FixedAsset.user_id == user_id,
            FixedAsset.status != 'disposed',
            FixedAsset.purchase_date <= end_date
        ).all()
        
        print(f"[æ•°æ®æŸ¥è¯¢] å›ºå®šèµ„äº§æ•°é‡: {len(assets)}")
        
        # è·å–æ—¶é—´èŒƒå›´å†…çš„æ”¶å…¥æ•°æ®
        incomes = AssetIncome.query.join(FixedAsset).filter(
            FixedAsset.user_id == user_id,
            AssetIncome.income_date >= start_date,
            AssetIncome.income_date <= end_date
        ).all()
        
        print(f"[æ•°æ®æŸ¥è¯¢] æ”¶å…¥è®°å½•æ•°é‡: {len(incomes)}")
        
        # è·å–åˆ†ç±»ä¿¡æ¯
        categories = Category.query.filter_by(user_id=user_id).all()
        
        # å›ºå®šèµ„äº§ç»Ÿè®¡æ•°æ®ï¼ˆæ·»åŠ NULLå€¼æ£€æŸ¥ï¼‰
        total_assets = len(assets)
        total_original_value = sum(
            float(asset.original_value) for asset in assets 
            if asset.original_value is not None
        )
        total_current_value = sum(
            float(asset.current_value) for asset in assets 
            if asset.current_value is not None
        )
        total_income = sum(
            float(income.amount) for income in incomes 
            if income.amount is not None
        )
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        category_stats = {}
        for category in categories:
            cat_assets = [a for a in assets if a.category_id == category.id]
            if cat_assets:
                category_stats[category.name] = {
                    'count': len(cat_assets),
                    'total_value': sum(
                        float(a.current_value) for a in cat_assets 
                        if a.current_value is not None
                    ),
                    'original_value': sum(
                        float(a.original_value) for a in cat_assets 
                        if a.original_value is not None
                    )
                }
        
        # æŒ‰çŠ¶æ€ç»Ÿè®¡
        status_stats = {}
        for asset in assets:
            status = asset.get_status_text()
            if status not in status_stats:
                status_stats[status] = 0
            status_stats[status] += 1
        
        # ========== è™šæ‹Ÿèµ„äº§ï¼ˆéšé£è€Œé€ï¼‰åˆ†æ ==========
        # è·å–ä¸æŠ¥å‘ŠæœŸç›¸å…³çš„è™šæ‹Ÿèµ„äº§é¡¹ç›®ï¼ˆæœ‰æ—¶é—´äº¤é›†çš„ï¼‰
        projects = Project.query.filter(
            Project.user_id == user_id,
            Project.start_time <= end_date,  # å¼€å§‹æ—¶é—´ä¸æ™šäºæŠ¥å‘ŠæœŸç»“æŸ
            Project.end_time >= start_date   # ç»“æŸæ—¶é—´ä¸æ—©äºæŠ¥å‘ŠæœŸå¼€å§‹
        ).all()
        
        print(f"[æ•°æ®æŸ¥è¯¢] è™šæ‹Ÿèµ„äº§é¡¹ç›®æ•°é‡: {len(projects)}")
        
        # è¿‡æ»¤æ‰æ•°æ®å¼‚å¸¸çš„é¡¹ç›®
        valid_projects = [
            p for p in projects 
            if p.total_amount is not None and p.end_time >= p.start_time
        ]
        
        if len(projects) != len(valid_projects):
            print(f"[æ•°æ®è­¦å‘Š] è¿‡æ»¤æ‰ {len(projects) - len(valid_projects)} ä¸ªå¼‚å¸¸é¡¹ç›®")
        
        # ç»Ÿè®¡è™šæ‹Ÿèµ„äº§æ•°æ®
        total_projects = len(valid_projects)
        total_project_amount = sum(float(p.total_amount) for p in valid_projects)
        
        # æŒ‰çŠ¶æ€åˆ†ç±»
        active_projects = []  # æ¶ˆè€—ä¸­
        expired_projects = []  # å·²è¿‡æœŸ
        not_started_projects = []  # æœªå¼€å§‹
        
        total_used_value = 0  # å·²æ¶ˆè€—æ€»ä»·å€¼
        total_remaining_value = 0  # å‰©ä½™æ€»ä»·å€¼ï¼ˆä»…æ´»è·ƒé¡¹ç›®ï¼‰
        total_wasted_value = 0  # æµªè´¹æ€»ä»·å€¼ï¼ˆè¿‡æœŸæœªç”¨å®Œï¼‰
        not_started_value = 0  # æœªå¼€å§‹é¡¹ç›®ä»·å€¼ï¼ˆå•ç‹¬ç»Ÿè®¡ï¼‰
        
        for project in valid_projects:
            status = project.get_status()
            values = project.calculate_values()
            
            if status == 'active':
                active_projects.append(project)
                total_used_value += values['used_cost']
                total_remaining_value += values['remaining_value']
            elif status == 'expired':
                expired_projects.append(project)
                total_used_value += values['used_cost']
                # è¿‡æœŸé¡¹ç›®çš„å‰©ä½™ä»·å€¼è§†ä¸ºæµªè´¹
                total_wasted_value += values['remaining_value']
            else:  # not_started
                not_started_projects.append(project)
                # æœªå¼€å§‹é¡¹ç›®å•ç‹¬ç»Ÿè®¡ï¼Œä¸è®¡å…¥å‰©ä½™ä»·å€¼
                not_started_value += float(project.total_amount)
        
        print(f"[æ•°æ®ç»Ÿè®¡] æ´»è·ƒ: {len(active_projects)}, è¿‡æœŸ: {len(expired_projects)}, æœªå¼€å§‹: {len(not_started_projects)}")
        
        # å³å°†è¿‡æœŸçš„é¡¹ç›®ï¼ˆ7å¤©å†…ï¼‰
        expiring_soon = []
        now = datetime.utcnow()
        for project in active_projects:
            days_left = (project.end_time - now).days
            if 0 <= days_left <= 7:
                expiring_soon.append({
                    'name': project.name,
                    'days_left': days_left,
                    'remaining_value': project.calculate_values()['remaining_value']
                })
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡è™šæ‹Ÿèµ„äº§
        project_category_stats = {}
        for category in categories:
            cat_projects = [p for p in valid_projects if p.category_id == category.id]
            if cat_projects:
                cat_total = sum(float(p.total_amount) for p in cat_projects)
                cat_wasted = 0
                for p in cat_projects:
                    if p.get_status() == 'expired':
                        cat_wasted += p.calculate_values()['remaining_value']
                
                project_category_stats[category.name] = {
                    'count': len(cat_projects),
                    'total_amount': cat_total,
                    'wasted_value': cat_wasted
                }
        
        # è™šæ‹Ÿèµ„äº§åˆ©ç”¨ç‡ï¼ˆä»…è®¡ç®—å·²å¼€å§‹çš„é¡¹ç›®ï¼‰
        started_amount = sum(
            float(p.total_amount) for p in (active_projects + expired_projects)
        )
        utilization_rate = (
            (total_used_value / started_amount * 100) 
            if started_amount > 0 else 0
        )
        
        # æµªè´¹ç‡ï¼ˆåŸºäºå·²å¼€å§‹çš„é¡¹ç›®ï¼‰
        waste_rate = (
            (total_wasted_value / started_amount * 100) 
            if started_amount > 0 else 0
        )
        
        print(f"[æ•°æ®ç»Ÿè®¡] åˆ©ç”¨ç‡: {utilization_rate:.2f}%, æµªè´¹ç‡: {waste_rate:.2f}%")
        
        return {
            # å›ºå®šèµ„äº§æ•°æ®
            'fixed_assets': {
                'total_assets': total_assets,
                'total_original_value': round(total_original_value, 2),
                'total_current_value': round(total_current_value, 2),
                'total_depreciation': round(total_original_value - total_current_value, 2),
                'total_income': round(total_income, 2),
                'depreciation_rate': round((total_original_value - total_current_value) / total_original_value * 100, 2) if total_original_value > 0 else 0,
                'category_stats': category_stats,
                'status_stats': status_stats
            },
            # è™šæ‹Ÿèµ„äº§æ•°æ®ï¼ˆéšé£è€Œé€ï¼‰
            'virtual_assets': {
                'total_projects': total_projects,
                'total_amount': round(total_project_amount, 2),
                'active_count': len(active_projects),
                'expired_count': len(expired_projects),
                'not_started_count': len(not_started_projects),
                'total_used_value': round(total_used_value, 2),
                'total_remaining_value': round(total_remaining_value, 2),  # ä»…æ´»è·ƒé¡¹ç›®
                'total_wasted_value': round(total_wasted_value, 2),
                'not_started_value': round(not_started_value, 2),  # å•ç‹¬ç»Ÿè®¡
                'utilization_rate': round(utilization_rate, 2),
                'waste_rate': round(waste_rate, 2),
                'expiring_soon': expiring_soon,
                'category_stats': project_category_stats
            },
            # ç»¼åˆè§†å›¾ï¼ˆéµå¾ªæ•°æ®é€»è¾‘éš”ç¦»åŸåˆ™ï¼‰
            'comprehensive': {
                'tangible_assets_value': round(total_current_value, 2),
                'active_rights_value': round(total_remaining_value, 2),
                'not_started_rights_value': round(not_started_value, 2),
                'combined_active_value': round(total_current_value + total_remaining_value, 2),
                'note': 'æœ‰å½¢èµ„äº§+æ´»è·ƒæƒç›Šï¼Œä¸åŒ…æ‹¬æœªå¼€å§‹é¡¹ç›®'
            },
            'period': {
                'start_date': start_date.isoformat(),
                'end_date': end_date.isoformat(),
                'days': (end_date - start_date).days + 1
            }
        }
    
    def generate_weekly_report(self, user_id, start_date, end_date, 
                              qualitative_analysis=None, intelligent_insights=None):
        """
        ç”Ÿæˆå‘¨æŠ¥ï¼ˆä¸‰é˜¶æ®µæµç¨‹ - çº¯æ–‡æœ¬ä¸­é—´æ ¼å¼ï¼‰
        :param user_id: ç”¨æˆ·ID
        :param start_date: å¼€å§‹æ—¥æœŸ
        :param end_date: ç»“æŸæ—¥æœŸ
        :param qualitative_analysis: ã€æ–°å¢ã€‘AIå®šæ€§åˆ†æç»“è®º
        :param intelligent_insights: ã€æ–°å¢ã€‘æ™ºèƒ½æ´å¯ŸæŒ‡æ ‡
        :return: æŠ¥å‘Šå†…å®¹ï¼ˆJSONæ ¼å¼ï¼‰
        """
        print("\n" + "#"*80)
        print("# å‘¨æŠ¥ç”Ÿæˆä¸‰é˜¶æ®µæµç¨‹å¼€å§‹")
        print("# æ³¨æ„ï¼šä¸­é—´é˜¶æ®µå…¨éƒ¨ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼ï¼Œæœ€ç»ˆè¾“å‡ºJSON")
        print("#"*80 + "\n")
        
        # ===== ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®æŸ¥è¯¢ï¼ˆå½“å‰æœŸ+ä¸ŠæœŸï¼‰ =====
        print("\n" + "="*80)
        print("[ç¬¬ä¸€é˜¶æ®µ] æ•°æ®æŸ¥è¯¢å¼€å§‹")
        print("="*80)
        
        # æŸ¥è¯¢å½“å‰æœŸæ•°æ®
        current_data = self.prepare_asset_data(user_id, start_date, end_date)
        print(f"âœ“ å½“å‰æœŸæ•°æ®æŸ¥è¯¢å®Œæˆ: {start_date} è‡³ {end_date}")
        
        # æŸ¥è¯¢ä¸ŠæœŸæ•°æ®ï¼ˆåŒç­‰æ—¶é•¿ï¼‰
        previous_data = self._get_previous_period_data(user_id, start_date, end_date)
        if previous_data:
            print(f"âœ“ ä¸ŠæœŸæ•°æ®æŸ¥è¯¢å®Œæˆ: {previous_data['period']['start_date']} è‡³ {previous_data['period']['end_date']}")
        else:
            print("âš  æœªæ‰¾åˆ°ä¸ŠæœŸæ•°æ®ï¼Œå°†ä»…åˆ†æå½“å‰æœŸæ•°æ®")
        
        print("="*80)
        print("[ç¬¬ä¸€é˜¶æ®µ] æ•°æ®æŸ¥è¯¢å®Œæˆ")
        print("="*80 + "\n")
        
        # ç«‹å³å°†ç»“æ„åŒ–æ•°æ®è½¬æ¢ä¸ºçº¯æ–‡æœ¬æ ¼å¼
        current_text = self._compress_data_to_text(current_data)
        print(f"\n[æ–‡æœ¬è½¬æ¢] å½“å‰æœŸæ•°æ®è½¬æ¢å®Œæˆ: {len(current_text)} å­—ç¬¦")
        
        # ç”Ÿæˆå¯¹æ¯”åˆ†ææ–‡æœ¬
        comparison_text = self._generate_comparison_text(current_data, previous_data) if previous_data else ""
        if comparison_text:
            print(f"[å¯¹æ¯”åˆ†æ] ç”Ÿæˆå¯¹æ¯”æ–‡æœ¬: {len(comparison_text)} å­—ç¬¦")
        
        # åˆå¹¶ä¸ºå®Œæ•´çš„æ•°æ®æ–‡æœ¬
        compressed_text = current_text + "\n\n" + comparison_text
        print(f"\n[æ–‡æœ¬é¢„è§ˆ]\n{compressed_text[:500]}...\n")
        
        # ===== ç¬¬äºŒé˜¶æ®µï¼šAIæ•°æ®é¢„åˆ†æï¼ˆå¯é€‰ï¼Œè¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯çº¯æ–‡æœ¬ï¼‰ =====
        ai_insights_text = self._preprocess_data_with_ai(compressed_text, enable_ai_insights=False)
        
        # ===== ç¬¬ä¸‰é˜¶æ®µï¼šç”ŸæˆæŠ¥å‘Šï¼ˆè¾“å…¥çº¯æ–‡æœ¬ï¼Œè¾“å‡ºMarkdownï¼‰ =====
        print("\n" + "="*80)
        print("[ç¬¬ä¸‰é˜¶æ®µ] æŠ¥å‘Šç”Ÿæˆå¼€å§‹")
        print("="*80)
        
        # ã€å¢å¼ºã€‘æ˜¾ç¤ºå®šæ€§åˆ†æä¿¡æ¯
        if qualitative_analysis:
            print("\nğŸ¯ [åˆ©ç”¨å®šæ€§åˆ†æ] AIå·²æä¾›å®šæ€§ç»“è®ºï¼Œå°†æŒ‡å¯¼æŠ¥å‘Šç”Ÿæˆ")
            print(f"  - æ•´ä½“è¯„ä¼°: {qualitative_analysis.get('overall_assessment')}")
            print(f"  - ç´§æ€¥ç¨‹åº¦: {qualitative_analysis.get('severity_level')}")
            print(f"  - å…³é”®é—®é¢˜: {len(qualitative_analysis.get('key_issues', []))}ä¸ª")
            print(f"  - é‡ç‚¹å…³æ³¨: {', '.join(qualitative_analysis.get('focus_areas', [])[:2])}")
        
        if intelligent_insights:
            print("\nğŸ“Š [æ™ºèƒ½æ´å¯Ÿ] å·²æä¾›æ™ºèƒ½æŒ‡æ ‡ï¼Œå°†å¢å¼ºåˆ†ææ·±åº¦")
            print(f"  - å›ºå®šèµ„äº§å¥åº·åº¦: {intelligent_insights.get('fixed_asset_health', 0):.1f}/100")
            print(f"  - è™šæ‹Ÿèµ„äº§æ•ˆç‡: {intelligent_insights.get('virtual_asset_efficiency', 0):.1f}/100")
        
        # æ„é€ æŠ¥å‘Šç”ŸæˆPromptï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶ï¼Œä¼ å…¥å¯¹æ¯”æ•°æ® + å®šæ€§åˆ†æï¼‰
        prompt = get_weekly_report_prompt(
            compressed_text, ai_insights_text, current_data, previous_data,
            intelligent_insights=intelligent_insights,  # ã€æ–°å¢ã€‘
            qualitative_analysis=qualitative_analysis   # ã€æ–°å¢ã€‘
        )
        print(f"[Promptç‰ˆæœ¬] {PROMPT_VERSION}")
        
        print(f"\n[æŠ¥å‘ŠPrompt] Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")
        print(f"\n[Promptå®Œæ•´å†…å®¹]\n{prompt}")
        print("\n" + "-"*80)
        
        print("\n[è°ƒç”¨API] å¼€å§‹ç”Ÿæˆå‘¨æŠ¥...")
        response_text = self._call_api(prompt)  # ä¸é™åˆ¶max_tokensï¼Œè®©æ¨¡å‹è‡ªç”±è¾“å‡º
        
        print(f"\n[APIå“åº”] å‘¨æŠ¥åŸå§‹å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
        print(f"\n[å‘¨æŠ¥Markdownå†…å®¹é¢„è§ˆ]\n{response_text[:1000]}...")
        print("\n" + "-"*80)
        
        # ç›´æ¥è¿”å›Markdownæ–‡æœ¬ï¼Œä¸éœ€è¦JSONè§£æ
        markdown_report = response_text.strip()
        
        # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
        if '```markdown' in markdown_report:
            markdown_report = markdown_report.split('```markdown')[1].split('```')[0].strip()
            print("[Markdownæ¸…ç†] ç§»é™¤äº†```markdown```æ ‡è®°")
        elif markdown_report.startswith('```') and markdown_report.endswith('```'):
            markdown_report = markdown_report.strip('`').strip()
            print("[Markdownæ¸…ç†] ç§»é™¤äº†ä»£ç å—æ ‡è®°")
        
        # ç”Ÿæˆå›¾è¡¨æ•°æ®
        chart_data = self._generate_chart_data(current_data, previous_data)
        print(f"[å›¾è¡¨æ•°æ®] å·²ç”Ÿæˆ{len(chart_data)}ä¸ªå›¾è¡¨")
        print(f"[å›¾è¡¨æ•°æ®è¯¦æƒ…]")
        for chart_name, chart_value in chart_data.items():
            print(f"  - {chart_name}: {len(chart_value) if isinstance(chart_value, list) else 'N/A'}é¡¹")
            if isinstance(chart_value, list) and len(chart_value) > 0:
                print(f"    ç¤ºä¾‹: {chart_value[0]}")
        
        # æ„é€ è¿”å›ç»“æœï¼ˆä¿æŒå…¼å®¹æ€§ï¼Œä½†ä¸»è¦å†…å®¹æ˜¯markdown + å›¾è¡¨æ•°æ®ï¼‰
        result = {
            "report_type": "markdown",
            "content": markdown_report,
            "chart_data": chart_data,  # æ–°å¢å›¾è¡¨æ•°æ®
            "intelligent_insights": intelligent_insights,  # ã€æ–°å¢ã€‘æ™ºèƒ½æ´å¯Ÿ
            "qualitative_analysis": qualitative_analysis,  # ã€æ–°å¢ã€‘å®šæ€§åˆ†æ
            "data_snapshot": current_data,
            "generated_at": current_data['period']['end_date']
        }
        
        print("\n" + "="*80)
        print("[ç¬¬ä¸‰é˜¶æ®µ] æŠ¥å‘Šç”Ÿæˆå®Œæˆ - æ–‡æœ¬æ ¼å¼")
        print("="*80)
        
        print("\n" + "#"*80)
        print("# å‘¨æŠ¥ç”Ÿæˆä¸‰é˜¶æ®µæµç¨‹ç»“æŸ")
        print("#"*80 + "\n")
        
        return json.dumps(result, ensure_ascii=False)
    
    def generate_monthly_report(self, user_id, start_date, end_date,
                               qualitative_analysis=None, intelligent_insights=None):
        """
        ç”ŸæˆæœˆæŠ¥ï¼ˆä¸‰é˜¶æ®µæµç¨‹ - Markdownæ ¼å¼ï¼‰
        :param qualitative_analysis: ã€æ–°å¢ã€‘AIå®šæ€§åˆ†æç»“è®º
        :param intelligent_insights: ã€æ–°å¢ã€‘æ™ºèƒ½æ´å¯ŸæŒ‡æ ‡
        """
        print("\n" + "#"*80)
        print("# æœˆæŠ¥ç”Ÿæˆä¸‰é˜¶æ®µæµç¨‹å¼€å§‹")
        print("# æ³¨æ„ï¼šä¸­é—´é˜¶æ®µå…¨éƒ¨ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼ï¼Œæœ€ç»ˆè¾“å‡ºMarkdown")
        print("#"*80 + "\n")
        
        # ===== ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®æŸ¥è¯¢ + ç«‹å³è½¬æ–‡æœ¬ =====
        print("\n" + "="*80)
        print("[ç¬¬ä¸€é˜¶æ®µ] æ•°æ®æŸ¥è¯¢å¼€å§‹")
        print("="*80)
        asset_data = self.prepare_asset_data(user_id, start_date, end_date)
        print("="*80)
        print("[ç¬¬ä¸€é˜¶æ®µ] æ•°æ®æŸ¥è¯¢å®Œæˆ")
        print("="*80 + "\n")
        
        # ç«‹å³å°†ç»“æ„åŒ–æ•°æ®è½¬æ¢ä¸ºçº¯æ–‡æœ¬æ ¼å¼
        compressed_text = self._compress_data_to_text(asset_data)
        print(f"\n[æ–‡æœ¬è½¬æ¢] å°†ç»“æ„åŒ–æ•°æ®è½¬æ¢ä¸ºçº¯æ–‡æœ¬: {len(compressed_text)} å­—ç¬¦")
        
        # ===== ç¬¬äºŒé˜¶æ®µï¼šAIæ•°æ®é¢„åˆ†æï¼ˆå¯é€‰ï¼Œè¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯çº¯æ–‡æœ¬ï¼‰ =====
        ai_insights_text = self._preprocess_data_with_ai(compressed_text, enable_ai_insights=False)
        
        # ===== ç¬¬ä¸‰é˜¶æ®µï¼šç”ŸæˆæŠ¥å‘Šï¼ˆè¾“å…¥çº¯æ–‡æœ¬ï¼Œè¾“å‡ºMarkdownï¼‰ =====
        print("\n" + "="*80)
        print("[ç¬¬ä¸‰é˜¶æ®µ] æŠ¥å‘Šç”Ÿæˆå¼€å§‹")
        print("="*80)
        
        # æ„é€ æŠ¥å‘Šç”ŸæˆPromptï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
        prompt = get_monthly_report_prompt(compressed_text, ai_insights_text, asset_data)
        print(f"[Promptç‰ˆæœ¬] {PROMPT_VERSION}")
        print(f"\n[æŠ¥å‘ŠPrompt] Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        print("\n[è°ƒç”¨API] å¼€å§‹ç”ŸæˆæœˆæŠ¥...")
        response_text = self._call_api(prompt)  # ä¸é™åˆ¶max_tokensï¼Œè®©æ¨¡å‹è‡ªç”±è¾“å‡º
        
        print(f"\n[APIå“åº”] æœˆæŠ¥åŸå§‹å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
        print(f"\n[æœˆæŠ¥Markdownå†…å®¹é¢„è§ˆ]\n{response_text[:1000]}...")
        print("\n" + "-"*80)
        
        # ç›´æ¥è¿”å›Markdownæ–‡æœ¬ï¼Œä¸éœ€è¦JSONè§£æ
        markdown_report = response_text.strip()
        
        # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
        if '```markdown' in markdown_report:
            markdown_report = markdown_report.split('```markdown')[1].split('```')[0].strip()
            print("[Markdownæ¸…ç†] ç§»é™¤äº†```markdown```æ ‡è®°")
        elif markdown_report.startswith('```') and markdown_report.endswith('```'):
            markdown_report = markdown_report.strip('`').strip()
            print("[Markdownæ¸…ç†] ç§»é™¤äº†ä»£ç å—æ ‡è®°")
        
        # æ„é€ è¿”å›ç»“æœï¼ˆä¿æŒå…¼å®¹æ€§ï¼Œä½†ä¸»è¦å†…å®¹æ˜¯markdownï¼‰
        result = {
            "report_type": "markdown",
            "content": markdown_report,
            "data_snapshot": asset_data,
            "generated_at": asset_data['period']['end_date']
        }
        
        print("\n" + "="*80)
        print("[ç¬¬ä¸‰é˜¶æ®µ] æŠ¥å‘Šç”Ÿæˆå®Œæˆ - æ–‡æœ¬æ ¼å¼")
        print("="*80)
        
        print("\n" + "#"*80)
        print("# æœˆæŠ¥ç”Ÿæˆä¸‰é˜¶æ®µæµç¨‹ç»“æŸ")
        print("#"*80 + "\n")
        
        return json.dumps(result, ensure_ascii=False)
    
    def generate_custom_report(self, user_id, start_date, end_date, focus_areas=None,
                              qualitative_analysis=None, intelligent_insights=None):
        """
        ç”Ÿæˆè‡ªå®šä¹‰æŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰
        :param user_id: ç”¨æˆ·ID
        :param start_date: å¼€å§‹æ—¥æœŸ
        :param end_date: ç»“æŸæ—¥æœŸ
        :param focus_areas: å…³æ³¨é¢†åŸŸåˆ—è¡¨
        :param qualitative_analysis: ã€æ–°å¢ã€‘AIå®šæ€§åˆ†æç»“è®º
        :param intelligent_insights: ã€æ–°å¢ã€‘æ™ºèƒ½æ´å¯ŸæŒ‡æ ‡
        :return: æŠ¥å‘Šå†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰
        """
        print("\n" + "#"*80)
        print("# è‡ªå®šä¹‰æŠ¥å‘Šç”Ÿæˆä¸‰é˜¶æ®µæµç¨‹å¼€å§‹")
        print("# æ³¨æ„ï¼šä¸­é—´é˜¶æ®µå…¨éƒ¨ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼ï¼Œæœ€ç»ˆè¾“å‡ºMarkdown")
        print("#"*80 + "\n")
        
        # ===== ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®æŸ¥è¯¢ + ç«‹å³è½¬æ–‡æœ¬ =====
        print("\n" + "="*80)
        print("[ç¬¬ä¸€é˜¶æ®µ] æ•°æ®æŸ¥è¯¢å¼€å§‹")
        print("="*80)
        asset_data = self.prepare_asset_data(user_id, start_date, end_date)
        print("="*80)
        print("[ç¬¬ä¸€é˜¶æ®µ] æ•°æ®æŸ¥è¯¢å®Œæˆ")
        print("="*80 + "\n")
        
        # ç«‹å³å°†ç»“æ„åŒ–æ•°æ®è½¬æ¢ä¸ºçº¯æ–‡æœ¬æ ¼å¼
        compressed_text = self._compress_data_to_text(asset_data)
        print(f"\n[æ–‡æœ¬è½¬æ¢] å°†ç»“æ„åŒ–æ•°æ®è½¬æ¢ä¸ºçº¯æ–‡æœ¬: {len(compressed_text)} å­—ç¬¦")
        
        # ===== ç¬¬äºŒé˜¶æ®µï¼šAIæ•°æ®é¢„åˆ†æï¼ˆå¯é€‰ï¼Œè¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯çº¯æ–‡æœ¬ï¼‰ =====
        ai_insights_text = self._preprocess_data_with_ai(compressed_text, enable_ai_insights=False)
        
        # ===== ç¬¬ä¸‰é˜¶æ®µï¼šç”ŸæˆæŠ¥å‘Šï¼ˆè¾“å…¥çº¯æ–‡æœ¬ï¼Œè¾“å‡ºMarkdownï¼‰ =====
        print("\n" + "="*80)
        print("[ç¬¬ä¸‰é˜¶æ®µ] æŠ¥å‘Šç”Ÿæˆå¼€å§‹")
        print("="*80)
        
        # æ·»åŠ ç‰¹åˆ«å…³æ³¨ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        focus_text = ""
        if focus_areas:
            focus_text = f"\n\nã€ç‰¹åˆ«å…³æ³¨ã€‘\nè¯·åœ¨æŠ¥å‘Šä¸­é‡ç‚¹åˆ†æä»¥ä¸‹æ–¹é¢ï¼š{', '.join(focus_areas)}\n"
            compressed_text += focus_text
        
        # æ„é€ æŠ¥å‘Šç”ŸæˆPromptï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
        prompt = get_custom_report_prompt(compressed_text, ai_insights_text, asset_data)
        print(f"[Promptç‰ˆæœ¬] {PROMPT_VERSION}")
        print(f"\n[æŠ¥å‘ŠPrompt] Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        print("\n[è°ƒç”¨API] å¼€å§‹ç”Ÿæˆè‡ªå®šä¹‰æŠ¥å‘Š...")
        response_text = self._call_api(prompt)  # ä¸é™åˆ¶max_tokensï¼Œè®©æ¨¡å‹è‡ªç”±è¾“å‡º
        
        print(f"\n[APIå“åº”] è‡ªå®šä¹‰æŠ¥å‘ŠåŸå§‹å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
        print(f"\n[è‡ªå®šä¹‰æŠ¥å‘ŠMarkdownå†…å®¹é¢„è§ˆ]\n{response_text[:1000]}...")
        print("\n" + "-"*80)
        
        # ç›´æ¥è¿”å›Markdownæ–‡æœ¬ï¼Œä¸éœ€è¦JSONè§£æ
        markdown_report = response_text.strip()
        
        # ç§»é™¤å¯èƒ½çš„ä»£ç å—æ ‡è®°
        if '```' in markdown_report:
            markdown_report = markdown_report.split('```')[1].split('```')[0].strip()
            print("[æ–‡æœ¬æ¸…ç†] ç§»é™¤äº†``æ ‡è®°")
        elif markdown_report.startswith('``') and markdown_report.endswith('```'):
            markdown_report = markdown_report.strip('`').strip()
            print("[æ–‡æœ¬æ¸…ç†] ç§»é™¤äº†ä»£ç å—æ ‡è®°")
        
        # æ„é€ è¿”å›ç»“æœï¼ˆä¿æŒå…¼å®¹æ€§ï¼Œä½†ä¸»è¦å†…å®¹æ˜¯æ–‡æœ¬ï¼‰
        result = {
            "report_type": "text",
            "content": markdown_report,
            "data_snapshot": asset_data,
            "generated_at": asset_data['period']['end_date'],
            "focus_areas": focus_areas if focus_areas else []
        }
        
        print("\n" + "="*80)
        print("[ç¬¬ä¸‰é˜¶æ®µ] æŠ¥å‘Šç”Ÿæˆå®Œæˆ - æ–‡æœ¬æ ¼å¼")
        print("="*80)
        
        print("\n" + "#"*80)
        print("# è‡ªå®šä¹‰æŠ¥å‘Šç”Ÿæˆä¸‰é˜¶æ®µæµç¨‹ç»“æŸ")
        print("#"*80 + "\n")
        
        return json.dumps(result, ensure_ascii=False)
