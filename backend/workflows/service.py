"""
æŠ¥å‘Šç”Ÿæˆå·¥ä½œæµæœåŠ¡å±‚
å°è£…å·¥ä½œæµè°ƒç”¨ã€çŠ¶æ€è·Ÿè¸ªã€é”™è¯¯å¤„ç†
"""
import logging
import asyncio
from datetime import datetime
from typing import Dict, Any, Optional
from workflows.state import ReportWorkflowState
from workflows.nodes import (
    init_task_node,
    collect_data_node,
    compress_data_node,
    agent_decide_comparison_node,
    query_previous_data_node,
    ai_preanalysis_node,
    generate_report_node,
    evaluate_quality_node,
    save_report_node,
    handle_retry_node,
    handle_failure_node
)
from workflows.routes import (
    route_after_decide_comparison,
    route_after_evaluation,
    route_after_retry
)


logger = logging.getLogger(__name__)


class ReportWorkflowService:
    """æŠ¥å‘Šç”Ÿæˆå·¥ä½œæµæœåŠ¡"""
    
    def __init__(self):
        self.logger = logger
    
    async def execute_workflow(self, task_context: Dict[str, Any]) -> ReportWorkflowState:
        """
        æ‰§è¡Œå®Œæ•´çš„æŠ¥å‘Šç”Ÿæˆå·¥ä½œæµ (LangGraphé©±åŠ¨)
        
        Args:
            task_context: ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«report_id, user_id, api_key, modelç­‰
        
        Returns:
            æœ€ç»ˆçš„å·¥ä½œæµçŠ¶æ€
        """
        self.logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡ŒLangGraphå·¥ä½œæµ - æŠ¥å‘ŠID: {task_context.get('report_id')}")
        
        # åˆå§‹åŒ–çŠ¶æ€
        state: ReportWorkflowState = {
            "task_context": task_context,
            "raw_data": None,
            "compressed_text": None,
            "previous_data": None,
            "comparison_text": None,
            "intelligent_insights": None,  # æ–°å¢
            "ai_insights": None,
            "report_content": None,
            "quality_score": None,
            "evaluation_result": None,
            "agent_decisions": [],
            "execution_path": [],
            "retry_count": 0,
            "max_retries": 3,
            "error_message": None,
            "start_time": datetime.utcnow().isoformat(),
            "end_time": None
        }
        
        try:
            # è·å–å·¥ä½œæµåº”ç”¨
            from workflows.graph import get_report_workflow
            workflow_app = get_report_workflow()
            
            if workflow_app is None:
                # é™çº§åˆ°æ‰‹åŠ¨æ‰§è¡Œæ¨¡å¼
                self.logger.warning("âš ï¸ LangGraphä¸å¯ç”¨ï¼Œä½¿ç”¨æ‰‹åŠ¨æ‰§è¡Œæ¨¡å¼")
                state = await self._execute_node_sequence(state)
            else:
                # ä½¿ç”¨LangGraphæ‰§è¡Œ
                self.logger.info("âœ… ä½¿ç”¨LangGraphå›¾é©±åŠ¨æ‰§è¡Œ")
                final_state = await workflow_app.ainvoke(state)
                state = final_state
            
            self.logger.info(f"âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ - æŠ¥å‘ŠID: {task_context.get('report_id')}")
            
        except Exception as e:
            self.logger.error(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
            import traceback
            self.logger.error(f"å †æ ˆä¿¡æ¯:\n{traceback.format_exc()}")
            state["error_message"] = str(e)
            state["end_time"] = datetime.utcnow().isoformat()
        
        return state
    
    async def _execute_node_sequence(self, state: ReportWorkflowState) -> ReportWorkflowState:
        """
        æ‰§è¡ŒèŠ‚ç‚¹åºåˆ—ï¼ˆæ‰‹åŠ¨å®ç°å·¥ä½œæµé€»è¾‘ï¼‰
        ç”±äºLangGraphå°šæœªå®‰è£…ï¼Œè¿™é‡Œç”¨ä¼ ç»Ÿæ–¹å¼å®ç°å·¥ä½œæµ
        """
        # N1: åˆå§‹åŒ–
        state = await init_task_node(state)
        if state.get("error_message"):
            return await handle_failure_node(state)
        
        # N2: æ•°æ®é‡‡é›†
        state = await collect_data_node(state)
        if state.get("error_message"):
            return await handle_failure_node(state)
        
        # N3: æ•°æ®å‹ç¼©
        state = await compress_data_node(state)
        if state.get("error_message"):
            return await handle_failure_node(state)
        
        # N4: Agentå†³ç­–æ˜¯å¦éœ€è¦ä¸ŠæœŸå¯¹æ¯”
        state = await agent_decide_comparison_node(state)
        next_node = route_after_decide_comparison(state)
        
        # N5: æŸ¥è¯¢ä¸ŠæœŸæ•°æ®ï¼ˆæ¡ä»¶ï¼‰
        if next_node == "query_previous_data":
            state = await query_previous_data_node(state)
        
        # N6: AIé¢„åˆ†æ
        state = await ai_preanalysis_node(state)
        
        # è¿›å…¥ç”Ÿæˆ-è¯„ä¼°-é‡è¯•å¾ªç¯
        while True:
            # N7: ç”ŸæˆæŠ¥å‘Š
            state = await generate_report_node(state)
            if state.get("error_message"):
                return await handle_failure_node(state)
            
            # N8: è´¨é‡è¯„ä¼°
            state = await evaluate_quality_node(state)
            
            # æ ¹æ®è¯„ä¼°ç»“æœè·¯ç”±
            next_action = route_after_evaluation(state)
            
            if next_action == "save_report":
                # N9: ä¿å­˜æŠ¥å‘Š
                state = await save_report_node(state)
                break
            
            elif next_action == "handle_retry":
                # N10: é‡è¯•å¤„ç†
                state = await handle_retry_node(state)
                # ç»§ç»­å¾ªç¯ï¼Œé‡æ–°ç”Ÿæˆ
                continue
            
            else:  # handle_failure
                # N11: å¤±è´¥å¤„ç†
                state = await handle_failure_node(state)
                break
        
        return state
    
    def get_workflow_visualization(self) -> Dict[str, Any]:
        """
        è·å–å·¥ä½œæµå¯è§†åŒ–æ•°æ®ï¼ˆMermaidæ ¼å¼ï¼‰
        """
        mermaid_graph = """
graph TD
    A[åˆå§‹åŒ–ä»»åŠ¡] --> B[æ•°æ®é‡‡é›†]
    B --> C[æ•°æ®å‹ç¼©]
    C --> D{Agentå†³ç­–<br/>éœ€è¦å¯¹æ¯”?}
    D -->|æ˜¯| E[æŸ¥è¯¢ä¸ŠæœŸæ•°æ®]
    D -->|å¦| F[AIé¢„åˆ†æ]
    E --> F
    F --> G[ç”ŸæˆæŠ¥å‘Š]
    G --> H[è´¨é‡è¯„ä¼°]
    H --> I{è¯„ä¼°ç»“æœ}
    I -->|åˆæ ¼| J[ä¿å­˜æŠ¥å‘Š]
    I -->|é‡è¯•| K[é‡è¯•å¤„ç†]
    I -->|å¤±è´¥| L[å¤±è´¥å¤„ç†]
    K --> G
    J --> M((ç»“æŸ))
    L --> M
    
    style A fill:#e1f5e1
    style J fill:#c8e6c9
    style L fill:#ffcdd2
    style D fill:#fff9c4
    style I fill:#fff9c4
"""
        
        return {
            "format": "mermaid",
            "graph": mermaid_graph,
            "nodes": [
                {"id": "init_task", "name": "åˆå§‹åŒ–ä»»åŠ¡", "type": "start"},
                {"id": "collect_data", "name": "æ•°æ®é‡‡é›†", "type": "process"},
                {"id": "compress_data", "name": "æ•°æ®å‹ç¼©", "type": "process"},
                {"id": "agent_decide_comparison", "name": "Agentå†³ç­–", "type": "decision"},
                {"id": "query_previous_data", "name": "æŸ¥è¯¢ä¸ŠæœŸæ•°æ®", "type": "process"},
                {"id": "ai_preanalysis", "name": "AIé¢„åˆ†æ", "type": "process"},
                {"id": "generate_report", "name": "ç”ŸæˆæŠ¥å‘Š", "type": "process"},
                {"id": "evaluate_quality", "name": "è´¨é‡è¯„ä¼°", "type": "process"},
                {"id": "save_report", "name": "ä¿å­˜æŠ¥å‘Š", "type": "end"},
                {"id": "handle_retry", "name": "é‡è¯•å¤„ç†", "type": "process"},
                {"id": "handle_failure", "name": "å¤±è´¥å¤„ç†", "type": "end"}
            ],
            "edges": [
                {"from": "init_task", "to": "collect_data", "type": "fixed"},
                {"from": "collect_data", "to": "compress_data", "type": "fixed"},
                {"from": "compress_data", "to": "agent_decide_comparison", "type": "fixed"},
                {"from": "agent_decide_comparison", "to": "query_previous_data", "type": "conditional", "condition": "éœ€è¦å¯¹æ¯”"},
                {"from": "agent_decide_comparison", "to": "ai_preanalysis", "type": "conditional", "condition": "æ— éœ€å¯¹æ¯”"},
                {"from": "query_previous_data", "to": "ai_preanalysis", "type": "fixed"},
                {"from": "ai_preanalysis", "to": "generate_report", "type": "fixed"},
                {"from": "generate_report", "to": "evaluate_quality", "type": "fixed"},
                {"from": "evaluate_quality", "to": "save_report", "type": "conditional", "condition": "åˆæ ¼"},
                {"from": "evaluate_quality", "to": "handle_retry", "type": "conditional", "condition": "é‡è¯•"},
                {"from": "evaluate_quality", "to": "handle_failure", "type": "conditional", "condition": "å¤±è´¥"},
                {"from": "handle_retry", "to": "generate_report", "type": "fixed"}
            ]
        }


# å…¨å±€æœåŠ¡å®ä¾‹
_workflow_service: Optional[ReportWorkflowService] = None


def get_workflow_service() -> ReportWorkflowService:
    """è·å–å·¥ä½œæµæœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _workflow_service
    
    if _workflow_service is None:
        _workflow_service = ReportWorkflowService()
    
    return _workflow_service
